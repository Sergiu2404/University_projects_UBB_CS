{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6962cf8-b5b7-4fa4-9d2d-5d2db98d00ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (hidden): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (output): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n",
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]])\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "Model Accuracy: 0.0%\n",
      "Model weights:\n",
      "hidden.weight tensor([[ 5.0780, -6.6407],\n",
      "        [ 1.7465, -0.3915],\n",
      "        [-4.3058, -4.7499],\n",
      "        [-6.0630,  3.8577]])\n",
      "hidden.weight tensor(5.0780)\n",
      "hidden.bias tensor([-2.3440,  0.4583,  1.0669, -1.5124])\n",
      "hidden.bias tensor(1.0669)\n",
      "output.weight tensor([[ 9.0624, -2.1759, -5.4511,  8.4026]])\n",
      "output.weight tensor(9.0624)\n",
      "output.bias tensor([-2.1479])\n",
      "output.bias tensor(-2.1479)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = nn.Sequential(OrderedDict([\n",
    "    ('hidden', nn.Linear(2, 4)),  # first hidden layer with 4 neurons\n",
    "    ('sigmoid', nn.Sigmoid()),    # sigmoid activation function\n",
    "    ('output', nn.Linear(4, 1)),  # output layer with 1 neuron\n",
    "    ('sigmoid', nn.Sigmoid())     # sigmoid activation function\n",
    "]))\n",
    "print(model)\n",
    "\n",
    "data_in = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float)\n",
    "print(data_in)\n",
    "\n",
    "data_target = torch.tensor([[0], [1], [1], [0]], dtype=torch.float)\n",
    "print(data_target)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# train the model\n",
    "losses = []\n",
    "for epoch in range(10000):\n",
    "    # reset the gradients to zero before each forward and backward pass\n",
    "    optimizer.zero_grad()    \n",
    "    outputs = model(data_in) # forward pass\n",
    "    loss = criterion(outputs, data_target) # calculate loss\n",
    "    loss.backward()          # backward pass\n",
    "    optimizer.step()         # update weights\n",
    "    losses.append(loss.item())\n",
    "    predicted_classes = (outputs.round() == data_target)\n",
    "    accuracy = predicted_classes.sum().item() / len(data_target)\n",
    "    if accuracy == 1:\n",
    "        print(f\"Model reached 100% accuracy at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "# model accuracy\n",
    "predicted = torch.round(outputs)\n",
    "correct = (predicted == data_target).sum()\n",
    "total = data_target.size(0)\n",
    "accuracy = correct / total\n",
    "print(f'Model Accuracy: {accuracy}%')    \n",
    "\n",
    "# visualize the resuts\n",
    "\n",
    "# print the best one of the weights for each layer\n",
    "print(f\"Model weights:\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "        print(name, torch.max(param.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "744006ea-cf63-40c3-8e5c-4291b56e35f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (hidden): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (output): Linear(in_features=3, out_features=2, bias=True)\n",
      ")\n",
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n",
      "Model 1 reached 100% accuracy at epoch 16\n",
      "Model Accuracy: 1.0%\n",
      "Model weights:\n",
      "hidden.weight tensor([[-0.1591, -0.1238],\n",
      "        [ 0.7153, -0.0021],\n",
      "        [ 0.6530, -0.4382]])\n",
      "hidden.bias tensor([ 0.5856,  0.3858, -0.2994])\n",
      "output.weight tensor([[ 0.5383,  0.3788, -0.1214],\n",
      "        [ 0.2268,  0.3535, -0.1654]])\n",
      "output.bias tensor([-0.2853,  0.1890])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model1 = nn.Sequential(OrderedDict([\n",
    "    ('hidden', nn.Linear(2, 3)),  # first hidden layer with 3 neurons\n",
    "    ('sigmoid', nn.Sigmoid()),    # sigmoid activation function\n",
    "    ('output', nn.Linear(3, 2)),  # output layer with 2 neurons\n",
    "    ('sigmoid', nn.Sigmoid())     # sigmoid activation function\n",
    "]))\n",
    "print(model1)\n",
    "\n",
    "data_in1 = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float)\n",
    "print(data_in1)\n",
    "\n",
    "data_target1 = torch.tensor([[0, 0], [0, 1], [0, 1], [1, 0]], dtype=torch.float)\n",
    "print(data_target1)\n",
    "\n",
    "criterion1 = nn.MSELoss()\n",
    "optimizer1 = torch.optim.SGD(model1.parameters(), lr=0.1)\n",
    "\n",
    "# train the model\n",
    "losses1 = []\n",
    "for epoch in range(10000):\n",
    "    # reset the gradients to zero before each forward and backward pass\n",
    "    optimizer1.zero_grad()  \n",
    "    # forward pass\n",
    "    outputs1 = model1(data_in1)\n",
    "    # calculate loss\n",
    "    loss1 = criterion1(outputs1, data_target1)\n",
    "    # backward pass\n",
    "    loss1.backward()          \n",
    "    # update weights\n",
    "    optimizer1.step()         \n",
    "    losses1.append(loss1.item())\n",
    "    \n",
    "    # accuracy\n",
    "    predicted_classes1 = (outputs1.round() == data_target1)\n",
    "    accuracy1 = predicted_classes1.sum().item() / len(data_target1)\n",
    "    if accuracy1 == 1:\n",
    "        print(f\"Model 1 reached 100% accuracy at epoch {epoch+1}\")\n",
    "        break\n",
    "        \n",
    "        \n",
    "# visualize the resuts\n",
    "predicted = torch.round(outputs1)\n",
    "correct = (predicted == data_target1).sum()\n",
    "total = data_target1.size(0)\n",
    "accuracy = correct / total\n",
    "print(f'Model Accuracy: {accuracy}%')  \n",
    "\n",
    "    \n",
    "# print model wights\n",
    "print(f\"Model weights:\")\n",
    "for name, param in model1.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58ce2ae0-a0e0-4c1b-8cf2-bc9cab6792c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (hidden): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (ReLU): ReLU()\n",
      "  (output): Linear(in_features=3, out_features=2, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.2543, 0.5003],\n",
      "        [0.2543, 0.5003],\n",
      "        [0.2543, 0.5003],\n",
      "        [0.2543, 0.5003]], grad_fn=<SigmoidBackward0>)\n",
      "Model Accuracy: 1.25%\n",
      "Model weights:\n",
      "hidden.weight tensor([[ 0.3944, -0.4629],\n",
      "        [ 0.2585, -0.3613],\n",
      "        [-0.6173, -0.0433]])\n",
      "hidden.bias tensor([-0.6005, -0.3915, -0.6767])\n",
      "output.weight tensor([[-0.3950,  0.5048,  0.1939],\n",
      "        [-0.2349,  0.4272,  0.5702]])\n",
      "output.bias tensor([-1.0761,  0.0012])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model1 = nn.Sequential(OrderedDict([\n",
    "    ('hidden', nn.Linear(2, 3)),  # first hidden layer with 3 neurons\n",
    "    ('ReLU', nn.ReLU()),          # relu activation function\n",
    "    ('output', nn.Linear(3, 2)),  # output layer with 3 neurons\n",
    "    ('sigmoid', nn.Sigmoid())     # sigmoid activation function\n",
    "]))\n",
    "print(model1)\n",
    "\n",
    "data_in1 = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float)\n",
    "print(data_in1)\n",
    "\n",
    "data_target1 = torch.tensor([[0, 0], [0, 1], [0, 1], [1, 0]], dtype=torch.float)\n",
    "print(data_target1)\n",
    "\n",
    "criterion1 = nn.MSELoss()\n",
    "optimizer1 = torch.optim.SGD(model1.parameters(), lr=0.1)\n",
    "\n",
    "# train the model\n",
    "losses1 = []\n",
    "for epoch in range(1000):\n",
    "    # reset the gradients to zero before each forward and backward pass\n",
    "    optimizer1.zero_grad()    \n",
    "    outputs1 = model1(data_in1) # forward pass\n",
    "    loss1 = criterion1(outputs1, data_target1) # calculate loss\n",
    "    loss1.backward()          # backward pass\n",
    "    optimizer1.step()         # update weights\n",
    "    losses1.append(loss1.item())\n",
    "    predicted_classes1 = (outputs1.round() == data_target1)\n",
    "    accuracy1 = predicted_classes1.sum().item() / len(data_target1)\n",
    "    if accuracy1 == 1:\n",
    "        print(f\"Model 1 reached 100% accuracy at epoch {epoch+1}\")\n",
    "        break\n",
    "        \n",
    "# visualize the results\n",
    "print(outputs1)\n",
    "predicted = torch.round(outputs1)\n",
    "correct = (predicted == data_target1).sum()\n",
    "total = data_target1.size(0)\n",
    "accuracy = correct / total\n",
    "print(f'Model Accuracy: {accuracy}%') \n",
    "\n",
    "# print model wights\n",
    "print(f\"Model weights:\")\n",
    "for name, param in model1.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7db53728-e15e-479e-abe5-c65cbc5072cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (hidden): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (ReLU): ReLU()\n",
      "  (output): Linear(in_features=3, out_features=2, bias=True)\n",
      "  (tanh): Tanh()\n",
      ")\n",
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n",
      "tensor([[0.0028, 0.5040],\n",
      "        [0.0028, 0.5040],\n",
      "        [0.0023, 0.9361],\n",
      "        [0.9411, 0.0023]], grad_fn=<TanhBackward0>)\n",
      "Model Accuracy: 1.75%\n",
      "Model weights:\n",
      "hidden.weight tensor([[ 0.8790, -0.8751],\n",
      "        [ 0.5926, -0.4622],\n",
      "        [ 1.1611,  0.8714]])\n",
      "hidden.bias tensor([-0.0036, -0.0012, -0.8758])\n",
      "output.weight tensor([[-0.5105,  0.0285,  1.5065],\n",
      "        [ 0.9976,  0.7401, -0.5606]])\n",
      "output.bias tensor([0.0028, 0.5546])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model1 = nn.Sequential(OrderedDict([\n",
    "    ('hidden', nn.Linear(2, 3)),  # first hidden layer with 3 neurons\n",
    "    ('ReLU', nn.ReLU()),          # relu activation function\n",
    "    ('output', nn.Linear(3, 2)),  # output layer with 3 neurons\n",
    "    ('tanh', nn.Tanh())     # sigmoid activation function\n",
    "]))\n",
    "print(model1)\n",
    "\n",
    "data_in1 = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float)\n",
    "print(data_in1)\n",
    "\n",
    "data_target1 = torch.tensor([[0, 0], [0, 1], [0, 1], [1, 0]], dtype=torch.float)\n",
    "print(data_target1)\n",
    "\n",
    "criterion1 = nn.MSELoss()\n",
    "optimizer1 = torch.optim.SGD(model1.parameters(), lr=0.1)\n",
    "\n",
    "# train the model\n",
    "losses1 = []\n",
    "for epoch in range(1000):\n",
    "    # reset the gradients to zero before each forward and backward pass\n",
    "    optimizer1.zero_grad()    \n",
    "    outputs1 = model1(data_in1) # forward pass\n",
    "    loss1 = criterion1(outputs1, data_target1) # calculate loss\n",
    "    loss1.backward()          # backward pass\n",
    "    optimizer1.step()         # update weights\n",
    "    losses1.append(loss1.item())\n",
    "    predicted_classes1 = (outputs1.round() == data_target1)\n",
    "    accuracy1 = predicted_classes1.sum().item() / len(data_target1)\n",
    "    if accuracy1 == 1:\n",
    "        print(f\"Model 1 reached 100% accuracy at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "# visualize the resuts\n",
    "print(outputs1)\n",
    "predicted = torch.round(outputs1)\n",
    "correct = (predicted == data_target1).sum()\n",
    "total = data_target1.size(0)\n",
    "accuracy = correct / total\n",
    "print(f'Model Accuracy: {accuracy}%') \n",
    "\n",
    "# print model wights\n",
    "print(f\"Model weights:\")\n",
    "for name, param in model1.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58701873-81e6-42cc-9433-159306aed830",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
